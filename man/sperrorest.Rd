% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sperrorest.R
\name{sperrorest}
\alias{sperrorest}
\title{Perform spatial error estimation and variable importance assessment in
parallel}
\usage{
sperrorest(
  formula,
  data,
  coords = c("x", "y"),
  model_fun,
  model_args = list(),
  pred_fun = NULL,
  pred_args = list(),
  smp_fun = partition_cv,
  smp_args = list(),
  train_fun = NULL,
  train_param = NULL,
  test_fun = NULL,
  test_param = NULL,
  err_fun = err_default,
  imp_variables = NULL,
  imp_permutations = 1000,
  importance = !is.null(imp_variables),
  distance = FALSE,
  do_gc = 1,
  progress = "all",
  benchmark = FALSE
)
}
\arguments{
\item{formula}{A formula specifying the variables used by the \code{model}. Only
simple formulas without interactions or nonlinear terms should be used,
e.g. \code{y~x1+x2+x3} but not \code{y~x1*x2+log(x3)}. Formulas involving interaction
and nonlinear terms may possibly work for error estimation but not for
variable importance assessment, but should be used with caution.}

\item{data}{a \code{data.frame} with predictor and response variables. Training
and test samples will be drawn from this data set by \code{train_fun} and
\code{test_fun}, respectively.}

\item{coords}{vector of length 2 defining the variables in \code{data} that
contain the x and y coordinates of sample locations.}

\item{model_fun}{Function that fits a predictive model, such as \code{glm} or
\code{rpart}. The function must accept at least two arguments, the first one
being a formula and the second a data.frame with the learning sample.}

\item{model_args}{Arguments to be passed to \code{model_fun} (in addition to the
\code{formula} and \code{data} argument, which are provided by {sperrorest})}

\item{pred_fun}{Prediction function for a fitted model object created by
\code{model}. Must accept at least two arguments: the fitted \code{object} and a
\code{data.frame} \code{newdata} with data on which to predict the outcome.}

\item{pred_args}{(optional) Arguments to \code{pred_fun} (in addition to the
fitted model object and the \code{newdata} argument, which are provided by
{sperrorest}).}

\item{smp_fun}{A function for sampling training and test sets from \code{data}.
E.g. \link{partition_kmeans} for spatial cross-validation using spatial
\emph{k}-means clustering.}

\item{smp_args}{(optional) Arguments to be passed to \code{smp_fun}.}

\item{train_fun}{(optional) A function for resampling or subsampling the
training sample in order to achieve, e.g., uniform sample sizes on all
training sets, or maintaining a certain ratio of positives and negatives in
training sets. E.g. \link{resample_uniform} or \link{resample_strat_uniform}.}

\item{train_param}{(optional) Arguments to be passed to \code{resample_fun}.}

\item{test_fun}{(optional) Like \code{train_fun} but for the test set.}

\item{test_param}{(optional) Arguments to be passed to \code{test_fun}.}

\item{err_fun}{A function that calculates selected error measures from the
known responses in \code{data} and the model predictions delivered by
\code{pred_fun}. E.g. \link{err_default} (the default).}

\item{imp_variables}{(optional; used if \code{importance = TRUE}). Variables for
which permutation-based variable importance assessment is performed. If
\code{importance = TRUE} and \code{imp_variables} == \code{NULL}, all variables in
\code{formula} will be used.}

\item{imp_permutations}{(optional; used if \code{importance = TRUE}). Number of
permutations used for variable importance assessment.}

\item{importance}{logical (default: \code{FALSE}): perform permutation-based
variable importance assessment?}

\item{distance}{logical (default: \code{FALSE}): if \code{TRUE}, calculate mean
nearest-neighbour distances from test samples to training samples using
\link{add.distance.represampling}.}

\item{do_gc}{numeric (default: 1): defines frequency of memory garbage
collection by calling \link{gc}; if \verb{< 1}, no garbage collection; if \verb{>= 1}, run
a \link{gc} after each repetition; if \verb{>= 2}, after each fold.}

\item{progress}{character (default: \code{all}): Whether to show progress
information (if possible). Default shows repetition, fold and (if enabled)
variable importance progress. Set to \code{"rep"} for repetition information
only or \code{FALSE} for no progress information.}

\item{benchmark}{(optional) logical (default: \code{FALSE}): if \code{TRUE}, perform
benchmarking and return \code{sperrorestbenchmark} object.}
}
\value{
A list (object of class {sperrorest}) with (up to) six components:
\itemize{
\item error_rep: \code{sperrorestreperror} containing
predictive performances at the repetition level
\item error_fold: \code{sperroresterror} object containing predictive
performances at the fold level
\item represampling: \link{represampling} object
\item importance: \code{sperrorestimportance} object containing
permutation-based variable importances at the fold level
\item benchmark: \code{sperrorestbenchmark} object containing
information on the system the code is running on, starting and
finishing times, number of available CPU cores and runtime performance
\item package_version: \code{sperrorestpackageversion} object containing
information about the {sperrorest} package version
}
}
\description{
{sperrorest} is a flexible interface for multiple types of
parallelized spatial and non-spatial cross-validation and bootstrap error
estimation and parallelized permutation-based assessment of spatial variable
importance.
}
\details{
Custom predict functions passed to \code{pred_fun}, which consist of
multiple child functions, must be defined in one function.
}
\section{Parallelization}{


Running in parallel is supported via package \CRANpkg{future}.
Have a look at \code{vignette("future-1-overview", package = "future")}.
In short: Choose a backend and specify the amount of workers, then call
\code{sperrorest()} as usual. Example:\if{html}{\out{<div class="r">}}\preformatted{future::plan(future.callr::callr, workers = 2)
sperrorest()
}\if{html}{\out{</div>}}
}

\examples{

## ------------------------------------------------------------
## Classification tree example using non-spatial partitioning
## ------------------------------------------------------------

# Muenchow et al. (2012), see ?ecuador
fo <- slides ~ dem + slope + hcurv + vcurv + log.carea + cslope

library(rpart)
mypred_part <- function(object, newdata) predict(object, newdata)[, 2]
ctrl <- rpart.control(cp = 0.005) # show the effects of overfitting
# show the effects of overfitting
fit <- rpart(fo, data = ecuador, control = ctrl)

### Non-spatial cross-validation:
mypred_part <- function(object, newdata) predict(object, newdata)[, 2]
nsp_res <- sperrorest(
  data = ecuador, formula = fo,
  model_fun = rpart,
  model_args = list(control = ctrl),
  pred_fun = mypred_part,
  progress = TRUE,
  smp_fun = partition_cv,
  smp_args = list(repetition = 1:2, nfold = 3)
)
summary(nsp_res$error_rep)
summary(nsp_res$error_fold)
summary(nsp_res$represampling)
# plot(nsp_res$represampling, ecuador)

### Spatial cross-validation:
sp_res <- sperrorest(
  data = ecuador, formula = fo,
  model_fun = rpart,
  model_args = list(control = ctrl),
  pred_fun = mypred_part,
  progress = TRUE,
  smp_fun = partition_kmeans,
  smp_args = list(repetition = 1:2, nfold = 3)
)
summary(sp_res$error_rep)
summary(sp_res$error_fold)
summary(sp_res$represampling)
# plot(sp_res$represampling, ecuador)

smry <- data.frame(
  nonspat_training = unlist(summary(nsp_res$error_rep,
    level = 1
  )$train_auroc),
  nonspat_test = unlist(summary(nsp_res$error_rep,
    level = 1
  )$test_auroc),
  spatial_training = unlist(summary(sp_res$error_rep,
    level = 1
  )$train_auroc),
  spatial_test = unlist(summary(sp_res$error_rep,
    level = 1
  )$test_auroc)
)
boxplot(smry,
  col = c("red", "red", "red", "green"),
  main = "Training vs. test, nonspatial vs. spatial",
  ylab = "Area under the ROC curve"
)
}
\references{
Brenning, A. 2012. Spatial cross-validation and bootstrap for
the assessment of prediction rules in remote sensing: the R package
'sperrorest'.
2012 IEEE International Geoscience and Remote Sensing Symposium (IGARSS),
23-27 July 2012, p. 5372-5375.

Brenning, A. 2005. Spatial prediction models for landslide hazards: review,
comparison and evaluation. Natural Hazards and Earth System Sciences,
5(6): 853-862.

Brenning, A., S. Long & P. Fieguth. Forthcoming. Detecting rock glacier flow
structures using Gabor filters and IKONOS imagery.
Submitted to Remote Sensing of Environment.

Russ, G. & A. Brenning. 2010a. Data mining in precision agriculture:
Management of spatial information. In 13th International Conference on
Information Processing and Management of Uncertainty, IPMU 2010; Dortmund;
28 June - 2 July 2010. Lecture Notes in Computer Science, 6178 LNAI: 350-359.

Russ, G. & A. Brenning. 2010b. Spatial variable importance assessment for
yield prediction in Precision Agriculture. In Advances in Intelligent
Data Analysis IX, Proceedings, 9th International Symposium,
IDA 2010, Tucson, AZ, USA, 19-21 May 2010.
Lecture Notes in Computer Science, 6065 LNCS: 184-195.
}
