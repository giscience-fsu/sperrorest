---
title: "sperrorest-vignette: Spatial modeling using statistical learning techniques"
author: "Alexander Brenning, Patrick Schratz"
date: "`r Sys.Date()`"
bibliography: ../Biblio.bib
csl: ../apa-old-doi-prefix.csl
output: 
    rmarkdown::html_vignette:
      toc: true
vignette: >
  %\VignetteIndexEntry{sperrorest-vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
```{r, echo=FALSE, cache=FALSE}
library(knitr)
opts_chunk$set(cache = TRUE,
               eval = TRUE, 
               fig.align = "center",
               collapse = TRUE,
               fig.width = 7,
               fig.height = 5)
opts_knit$set(width = 125)
```

# Data And Packages

```{r, message=FALSE}
library(rpart)
library(MASS)
library(ipred)
library(sperrorest)
```

The `maipo` data set from Marco Pena is used. 
```{r}
data("maipo", package = "sperrorest")
```

Variable description:

**Response**  
  - `croptype`: response variable (factor) with 4 levels  
  
**Predictors**  
  - `b`[12-87]: spectral data, e.g. b82 = image date #8, spectral band #2  
  - `ndvi`[01-08]: Normalized Differenced Vegetation Index, e.g. #8 = image date #8  
  - `ndwi`[01-08]: Normalized Differenced Water Index, e.g. #8 = image date #8  
  
**Others**  
  - `field`: field identifier (grouping variable - not to be used as predictor)  
  - `utmx`, `utmy`: x/y location; not to be used as predictors  

# Preprocessing

Transformation of some predictor variables:

```{r}
predictors <- colnames(maipo)[5:ncol(maipo)]
# Construct a formula:
fo <- as.formula(paste("croptype ~", paste(predictors, collapse = "+")))
```

Quick look at (some) correlations among the predictors:
```{r}
co <- abs(cor(maipo[, predictors]) * 100)
co[co < 70] <- 0 # mask out weak/moderate correlations
head(round(co))
```


# Modeling

## Linear Discriminant Analysis (LDA)

Fit a model with all predictors:
```{r}
fit <- lda(fo, data = maipo)
```

Predict the croptype with the fitted model and calculate the average misclassification error rate (MER):
```{r}
pred <- predict(fit, newdata = maipo)$class
mean(pred != maipo$croptype)
```

Take a look at the confusion matrix:
```{r}
table(pred = pred, obs = maipo$croptype)
```


## Classification Tree

Fit a model with all predictors:

```{r}
fit <- rpart(fo, data = maipo)
#            control = rpart.control(cp=0.01))

## optional: view the classiciation tree
# par(xpd = TRUE)
# plot(fit)
# text(fit, use.n = TRUE)
```

Again, predict the croptype with the fitted model and calculate the average MER:
```{r}
pred <- predict(fit, newdata = maipo, type = "class")
mean(pred != maipo$croptype)
```

And take a look at the confusion matrix:
```{r}
table(pred = pred, obs = maipo$croptype)
```

Note that some classes may be over-/underpredicted, i.e. remotely-sensed crop areas can be biased even if accuracy is high!

```{r}
summary(pred)
summary(maipo$croptype)
```

## Bagging (ipred)

The same can be done using the `bagging()` function from the `ipred` package [@Breiman1996]. This is a previous version of the famous `randomForest()` by Leo Breiman [@Breiman2001]. For some reason `randomForest()` does introduce problems when being paralized. Hence `bagging()` is used in this vignette. However, `randomForest()` works fine with the sequential `sperrorest()` function and should be prefered over `bagging()`. 

```{r}
fit <- bagging(fo, data = maipo, coob = TRUE)
fit
```
Training-set misclassification error rate (MER) 
```{r}
pred <- predict(fit, newdata = maipo, type = "class")
mean(pred != maipo$croptype)
```

Confusion matrix:
```{r}
table(pred = pred, obs = maipo$croptype)
```

- Almost no missclassification! (only one observation)
- Even the OOB (out-of-bag) estimate of the error rate is < 1%.
- Too good to be true? We'll see...

# Cross-Validation Estimation of Predictive Performance

## Linear Discriminant Analysis (LDA)

We need to set up some functions to create a wrapper predict function of the LDA model for `sperrorest()`. 

```{r}
lda.predfun <- function(object, newdata, fac = NULL) {
  library(nnet)
  majority <- function(x) {
    levels(x)[which.is.max(table(x))]
  }
  
  majority.filter <- function(x, fac) {
    for (lev in levels(fac)) {
      x[ fac == lev ] <- majority(x[ fac == lev ])
    }
    x
  }
  
  pred <- predict(object, newdata = newdata)$class
  if (!is.null(fac)) pred <- majority.filter(pred, newdata[,fac]) 
  return(pred)
}
```

Finally, we can run `sperrorest()` with a non-spatial sampling setup (`partition.cv()`):

```{r}
res.lda.nsp <- res <- sperrorest(fo, data = maipo, coords = c("utmx","utmy"), 
                                 model.fun = lda,
                                 pred.fun = lda.predfun, 
                                 pred.args = list(fac = "field"),
                                 smp.fun = partition.cv, 
                                 smp.args = list(repetition = 1:6, nfold = 5),
                                 error.rep = TRUE, error.fold = FALSE)
round(summary(res.lda.nsp$error.rep), 3)
```

To run a spatial cross-validation at the field level, we can use `partition.factor.cv()` as the sampling function. Subsequently, we have to specify the location of the fields. We can do so using the `field` variable of our data set and put in `smp.args`: 

```{r}
res.lda.sp <- sperrorest(fo, data = maipo, coords = c("utmx","utmy"), 
                         model.fun = lda,
                         pred.fun = lda.predfun, 
                         pred.args = list(fac = "field"),
                         smp.fun = partition.factor.cv,
                         smp.args = list(fac = "field", repetition = 1:6, nfold = 5),
                         error.rep = TRUE, error.fold = FALSE, 
                         benchmark = TRUE)
res.lda.sp$benchmark$runtime.performance
```

The same can be done faster using `parsperrorest()`. 
```{r}
res.lda.sp.par <- parsperrorest(fo, data = maipo, coords = c("utmx","utmy"), 
                                model.fun = lda,
                                pred.fun = lda.predfun, 
                                pred.args = list(fac = "field"),
                                smp.fun = partition.factor.cv,
                                smp.args = list(fac = "field", repetition = 1:6, nfold = 5),
                                par.args = list(par.units = 2, par.mode = 2),
                                error.rep = TRUE, error.fold = TRUE,
                                benchmark = TRUE)
res.lda.sp.par$benchmark$runtime.performance
```


```{r}
res.lda.par <- parsperrorest(fo, data = maipo, coords = c("utmx","utmy"), 
                               model.fun = lda,
                               pred.fun = lda.predfun, 
                               pred.args = list(fac = "field"),
                               smp.fun = partition.cv,
                               smp.args = list(repetition = 1:6, nfold = 5),
                               par.args = list(par.units = 2, par.mode = 2),
                               error.rep = TRUE, error.fold = TRUE,
                               benchmark = TRUE)
res.lda.sp.par$benchmark$runtime.performance
```

## Bagging

This time we do not need to set up a custom `pred.fun` as the generic `predict()` works fine. 
Running `sperrorest()` takes some time here (a few minutes depending on your CPU power). 


```{r}
res.bagg.sp <- sperrorest(fo, data = maipo, coords = c("utmx","utmy"), 
                          model.fun = bagging,
                          pred.args = list(fac = "field"),
                          smp.fun = partition.factor.cv,
                          smp.args = list(fac = "field",
                                          repetition = 1:6, nfold = 5),
                          error.rep = TRUE, error.fold = TRUE,
                          benchmark = TRUE, verbose = "rep")
res.bagg.sp$benchmark$runtime.performance
```

To speed things up, we can use `parsperrorest()` and see the time difference. Note that we have two parallel modes to choose from!  
In this example we will use `par.mode = 2` because `par.mode = 1` will not work in this example (reason unknown). 
In this vignette we will always use 2 cores to ensure that this example is working for everybody.  
You can of course increase the number of cores and also the number of repetitions/folds to your desire! 
Note that we will not use any console outputs in this vignette to keep it tidy.
However you can just change this setting to your desire using the `progress` argument. 

#### Details of par.mode

`par.mode = 1` uses either a `parallel::mclapply()` (Unix) or `parallel::parApply()` (Windows), depending on your platform.
Due to this contraint this mode is not used in this vignette. 
So if you are reading this and running a Windows machine, jump to `par.mode = 2` or `par.mode = 3` example!
The advantage of using `par.mode = 1` compared to `par.mode = 2` is its speed. However `par.mode = 1` lacks in stability. 


```{r}
res.bagg.sp.par <- parsperrorest(fo, data = maipo, coords = c("utmx","utmy"), 
                                 model.fun = bagging,
                                 pred.args = list(fac = "field"),
                                 smp.fun = partition.factor.cv,
                                 smp.args = list(fac = "field", 
                                                 repetition = 1:6, nfold = 5),
                                 par.args = list(par.units = 2, par.mode = 2),
                                 error.rep = TRUE, error.fold = TRUE,
                                 benchmark = TRUE)
res.bagg.sp.par$benchmarks$runtime.performance
```

# References
